@article{moller_bedeutung_2017,
	title = {Bedeutung von Daten im Zeitalter der Digitalisierung},
	url = {https://publica.fraunhofer.de/handle/publica/298614},
	doi = {10.24406/IML-N-462115},
	abstract = {Die wachsende Bedeutung der Ressource Daten in der Erstellung hybrider oder rein digitaler Geschäftsmodelle stellen Unternehmen stetig vor neue Herausforderungen. Die Perspektive Daten des Leistungszentrums Logistik und {IT} unterstützt die Unternehmen durch eine ganzheitliche und wissenschaftlich fundierte Betrachtung von der Modellierung über die Architektur und Verwendung konkreter Technologien.},
	author = {Möller, Frederik and Spiekermann, Markus and Burmann, Anja and Pettenpohl, Heinrich},
	editora = {Ten Hompel, Michael and Henke, Michael and Clausen, Uwe},
	editoratype = {collaborator},
	urldate = {2024-10-31},
	date = {2017},
	note = {Publisher: Fraunhofer {IML}},
	keywords = {Advanced Data Processing Technologies, Data Network Engineering, Daten, Digital Business Engineering, Industrie 4.0, Logistik 4.0},
}

@article{tolk_common_2003,
	title = {Common Data Administration, Data Management, and Data Alignment as a Necessary Requirement for Coupling C4ISR Systems and M\&S Systems},
	volume = {12},
	issn = {08615160},
	url = {http://www.procon.bg/node/2553},
	doi = {10.11610/isij.1209},
	pages = {164--174},
	journaltitle = {Information \& Security: An International Journal},
	shortjournal = {{ISIJ}},
	author = {Tolk, Andreas},
	urldate = {2024-10-31},
	date = {2003},
	langid = {english},
}

@book{weber_data_2021,
	location = {Wiesbaden},
	title = {Data Engineering 4.0: Kompositionale Informationsmodelle für industrielle Anwendungen},
	rights = {https://www.springer.com/tdm},
	isbn = {978-3-658-33184-9 978-3-658-33185-6},
	url = {https://link.springer.com/10.1007/978-3-658-33185-6},
	shorttitle = {Data Engineering 4.0},
	publisher = {Springer Fachmedien},
	author = {Weber, Herbert},
	urldate = {2024-10-31},
	date = {2021},
	langid = {german},
	doi = {10.1007/978-3-658-33185-6},
	keywords = {Data Engineering, Daten, Extensionale Konstruktion, Industrie 4.0, Informationen, Informationsmodelle, Intensionale Konstruktion, Konstruktion, Makromodellierung, Mikromodellierung, Modellieren},
}

@article{schulze_balhorn_empirical_2024,
	title = {Empirical assessment of {ChatGPT}’s answering capabilities in natural science and engineering},
	volume = {14},
	rights = {2024 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-54936-7},
	doi = {10.1038/s41598-024-54936-7},
	abstract = {{ChatGPT} is a powerful language model from {OpenAI} that is arguably able to comprehend and generate text. {ChatGPT} is expected to greatly impact society, research, and education. An essential step to understand {ChatGPT}’s expected impact is to study its domain-specific answering capabilities. Here, we perform a systematic empirical assessment of its abilities to answer questions across the natural science and engineering domains. We collected 594 questions on natural science and engineering topics from 198 faculty members across five faculties at Delft University of Technology. After collecting the answers from {ChatGPT}, the participants assessed the quality of the answers using a systematic scheme. Our results show that the answers from {ChatGPT} are, on average, perceived as “mostly correct”. Two major trends are that the rating of the {ChatGPT} answers significantly decreases (i) as the educational level of the question increases and (ii) as we evaluate skills beyond scientific knowledge, e.g., critical attitude.},
	pages = {4998},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Schulze Balhorn, Lukas and Weber, Jana M. and Buijsman, Stefan and Hildebrandt, Julian R. and Ziefle, Martina and Schweidtmann, Artur M.},
	urldate = {2024-11-02},
	date = {2024-02-29},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational science, Computer science, Engineering},
}

@online{noauthor_introducing_2022,
	title = {Introducing {ChatGPT}},
	url = {https://openai.com/index/chatgpt/},
	abstract = {We’ve trained a model called {ChatGPT} which interacts in a conversational way. The dialogue format makes it possible for {ChatGPT} to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.},
	urldate = {2024-10-31},
	date = {2022-11-30},
	langid = {american},
}

@article{schinkels_ki-halluzinationen_2024,
	location = {Hamburg},
	title = {{KI}-Halluzinationen: Wer fabuliert hier so herum?},
	issn = {0044-2070},
	url = {https://www.zeit.de/digital/2024-06/ki-halluzinationen-sprachmodelle-erkennung-universitaet-oxford},
	shorttitle = {{KI}-Halluzinationen},
	abstract = {Chatbots wie {ChatGPT} verbreiten Falschantworten, das ist ein Problem. Forscher haben eine Methode entwickelt, wie sie solche Halluzinationen besser erkennen wollen.},
	journaltitle = {Die Zeit},
	author = {Schinkels, Pauline},
	urldate = {2024-10-31},
	date = {2024-06-23},
	langid = {german},
	keywords = {{ChatGPT}, Forschung, Software, Studie, künstliche Intelligenz},
}

@article{cha_paul_2015,
	title = {Paul Allen’s {AI} research group unveils program that aims to shake up how we search scientific knowledge. Give it a try.},
	issn = {0190-8286},
	url = {https://www.washingtonpost.com/news/to-your-health/wp/2015/11/02/paul-allens-ai-research-group-unveils-program-that-aims-to-shake-up-how-we-search-scientific-knowledge-give-it-a-try/},
	abstract = {The program, known as Semantic Scholar, searches journal articles in a new way.},
	journaltitle = {Washington Post},
	author = {Cha, Ariana Eunjung},
	urldate = {2024-10-31},
	date = {2015-11-02},
	langid = {american},
}

@misc{zhao_retrieval-augmented_2024,
	title = {Retrieval-Augmented Generation for {AI}-Generated Content: A Survey},
	url = {http://arxiv.org/abs/2402.19473},
	doi = {10.48550/arXiv.2402.19473},
	shorttitle = {Retrieval-Augmented Generation for {AI}-Generated Content},
	abstract = {Advancements in model algorithms, the growth of foundational models, and access to high-quality datasets have propelled the evolution of Artificial Intelligence Generated Content ({AIGC}). Despite its notable successes, {AIGC} still faces hurdles such as updating knowledge, handling long-tail data, mitigating data leakage, and managing high training and inference costs. Retrieval-Augmented Generation ({RAG}) has recently emerged as a paradigm to address such challenges. In particular, {RAG} introduces the information retrieval process, which enhances the generation process by retrieving relevant objects from available data stores, leading to higher accuracy and better robustness. In this paper, we comprehensively review existing efforts that integrate {RAG} technique into {AIGC} scenarios. We first classify {RAG} foundations according to how the retriever augments the generator, distilling the fundamental abstractions of the augmentation methodologies for various retrievers and generators. This unified perspective encompasses all {RAG} scenarios, illuminating advancements and pivotal technologies that help with potential future progress. We also summarize additional enhancements methods for {RAG}, facilitating effective engineering and implementation of {RAG} systems. Then from another view, we survey on practical applications of {RAG} across different modalities and tasks, offering valuable references for researchers and practitioners. Furthermore, we introduce the benchmarks for {RAG}, discuss the limitations of current {RAG} systems, and suggest potential directions for future research. Github: https://github.com/{PKU}-{DAIR}/{RAG}-Survey.},
	number = {{arXiv}:2402.19473},
	publisher = {{arXiv}},
	author = {Zhao, Penghao and Zhang, Hailin and Yu, Qinhan and Wang, Zhengren and Geng, Yunteng and Fu, Fangcheng and Yang, Ling and Zhang, Wentao and Jiang, Jie and Cui, Bin},
	urldate = {2024-10-31},
	date = {2024-06-21},
	eprinttype = {arxiv},
	eprint = {2402.19473},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{aylsworth_should_2024,
	title = {Should I Use {ChatGPT} to Write My Papers?},
	volume = {37},
	issn = {2210-5441},
	url = {https://doi.org/10.1007/s13347-024-00809-w},
	doi = {10.1007/s13347-024-00809-w},
	abstract = {We argue that students have moral reasons to refrain from using chatbots such as {ChatGPT} to write certain papers. We begin by showing why many putative reasons to refrain from using chatbots fail to generate compelling arguments against their use in the construction of these papers. Many of these reasons rest on implausible principles, hollowed out conceptions of education, or impoverished accounts of human agency. They also overextend to cases where it is permissible to rely on a machine for something that once required human cognition. We then give our account: you have a moral obligation to respect your own humanity (i.e., your capacity to set and pursue your own ends), and the process of writing a humanities paper is important for the cultivation of your humanity. We conclude by considering objections and offering replies. In the end, we argue that the moral reasons students have to refrain from using chatbots depend crucially on instructors’ ability to make writing assignments worthwhile. This relies on instructors having the right kind of institutional support, which sheds light on implications that this duty has for administrators, legislators, and the general public.},
	pages = {117},
	number = {4},
	journaltitle = {Philosophy \& Technology},
	shortjournal = {Philos. Technol.},
	author = {Aylsworth, Timothy and Castro, Clinton},
	urldate = {2024-11-02},
	date = {2024-10-01},
	langid = {english},
	keywords = {Autonomy, {ChatGPT}, Duties to oneself, Ethics of technology, Kantian ethics},
}

@inproceedings{ostendorff_specialized_2022,
	location = {New York, {NY}, {USA}},
	title = {Specialized document embeddings for aspect-based similarity of research papers},
	isbn = {978-1-4503-9345-4},
	url = {https://dl.acm.org/doi/10.1145/3529372.3530912},
	doi = {10.1145/3529372.3530912},
	series = {{JCDL} '22},
	abstract = {Document embeddings and similarity measures underpin content-based recommender systems, whereby a document is commonly represented as a single generic embedding. However, similarity computed on single vector representations provides only one perspective on document similarity that ignores which aspects make two documents alike. To address this limitation, aspect-based similarity measures have been developed using document segmentation or pairwise multi-class document classification. While segmentation harms the document coherence, the pairwise classification approach scales poorly to large scale corpora. In this paper, we treat aspect-based similarity as a classical vector similarity problem in aspect-specific embedding spaces. We represent a document not as a single generic embedding but as multiple specialized embeddings. Our approach avoids document segmentation and scales linearly w.r.t. the corpus size. In an empirical study, we use the Papers with Code corpus containing 157, 606 research papers and consider the task, method, and dataset of the respective research papers as their aspects. We compare and analyze three generic document embeddings, six specialized document embeddings and a pairwise classification baseline in the context of research paper recommendations. As generic document embeddings, we consider {FastText}, {SciBERT}, and {SPECTER}. To compute the specialized document embeddings, we compare three alternative methods inspired by retrofitting, fine-tuning, and Siamese networks. In our experiments, Siamese {SciBERT} achieved the highest scores. Additional analyses indicate an implicit bias of the generic document embeddings towards the dataset aspect and against the method aspect of each research paper. Our approach of aspect-based document embeddings mitigates potential risks arising from implicit biases by making them explicit. This can, for example, be used for more diverse and explainable recommendations.},
	pages = {1--12},
	booktitle = {Proceedings of the 22nd {ACM}/{IEEE} Joint Conference on Digital Libraries},
	publisher = {Association for Computing Machinery},
	author = {Ostendorff, Malte and Blume, Till and Ruas, Terry and Gipp, Bela and Rehm, Georg},
	urldate = {2024-10-31},
	date = {2022-06-20},
}

@inproceedings{lahoti_specter-based_2023,
	title = {{SPECTER}-Based Transformer Model For Multi-Label Research Paper Classification},
	url = {https://ieeexplore.ieee.org/abstract/document/10450144},
	doi = {10.1109/PuneCon58714.2023.10450144},
	abstract = {The ever-increasing number of research and academia publications presents new problems for future researchers and publication libraries, such as difficulty finding the proper papers for literature reviews due to cluttered data and inadequate keywords. It also hinders academic libraries from creating adequate indexing and leads to more and more unstructured data. This paper proposes a novel solution for classifying published research and scholarly articles, which would help solve the given problems by facilitating improved search engine optimization for online academic libraries. The study method utilizes the openly available {arXiv} dataset of 2.3 million records containing the metadata for each published research paper, which includes the title and the abstract. It uses the paper's metadata as the input and outputs multiple labels related to the input domain. The research compared different techniques for multi-label classification tasks and proposed a Specter method, which uses a transformer-based model for the task of research article classification. This method achieved a significant increase in precision and accuracy on the dataset and will help improve the maintenance of scholarly articles and make relevant works more readily available.},
	eventtitle = {2023 {IEEE} Pune Section International Conference ({PuneCon})},
	pages = {1--7},
	booktitle = {2023 {IEEE} Pune Section International Conference ({PuneCon})},
	author = {Lahoti, Kushal and Ahuja, Vrinda and Patil, Archana},
	urldate = {2024-10-31},
	date = {2023-12},
	note = {{ISSN}: 2831-5022},
	keywords = {Attention, {BERT}, Deep Learning, Libraries, Maintenance engineering, Metadata, Multi-Label Classification ({MLC}), Optimization, Search engines, Specter, {TF}-{IDF}, Task analysis, Transformer, Transformers, Word Embedding, {arXiv}},
}

@misc{cohan_specter_2020,
	title = {{SPECTER}: Document-level Representation Learning using Citation-informed Transformers},
	url = {http://arxiv.org/abs/2004.07180},
	doi = {10.48550/arXiv.2004.07180},
	shorttitle = {{SPECTER}},
	abstract = {Representation learning is a critical ingredient for natural language processing systems. Recent Transformer language models like {BERT} learn powerful textual representations, but these models are targeted towards token- and sentence-level training objectives and do not leverage information on inter-document relatedness, which limits their document-level representation power. For applications on scientific documents, such as classification and recommendation, the embeddings power strong performance on end tasks. We propose {SPECTER}, a new method to generate document-level embedding of scientific documents based on pretraining a Transformer language model on a powerful signal of document-level relatedness: the citation graph. Unlike existing pretrained language models, {SPECTER} can be easily applied to downstream applications without task-specific fine-tuning. Additionally, to encourage further research on document-level models, we introduce {SciDocs}, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation. We show that {SPECTER} outperforms a variety of competitive baselines on the benchmark.},
	number = {{arXiv}:2004.07180},
	publisher = {{arXiv}},
	author = {Cohan, Arman and Feldman, Sergey and Beltagy, Iz and Downey, Doug and Weld, Daniel S.},
	urldate = {2024-10-31},
	date = {2020-05-20},
	eprinttype = {arxiv},
	eprint = {2004.07180},
	keywords = {Computer Science - Computation and Language},
}

@article{ali_spr-smn_2022,
	title = {{SPR}-{SMN}: scientific paper recommendation employing {SPECTER} with memory network},
	volume = {127},
	issn = {1588-2861},
	url = {https://doi.org/10.1007/s11192-022-04425-3},
	doi = {10.1007/s11192-022-04425-3},
	shorttitle = {{SPR}-{SMN}},
	abstract = {During the last decades, recommender systems are becoming quite popular since they provide great assistance to users on social networks and library websites. Unfortunately, the large volume of data combined with sparsity makes personalization a difficult task. In this regard, several models were introduced in the literature that suffers from the cold-start problem and the lack of personalization. In particular, the majority of these models ignore the relationship between the important factors and the semantic relations among the nodes (the authors, and the field of study) on the heterogeneous papers networks. Moreover, they fail to effectively capture researchers’ preferences, which leads to inadequate recommendations. To overcome these problems, with this study we propose a scientific paper recommendation model called {SPR}-{SMN}, which employs the {SPECTER} document embedding model to learn context-preserving paper content representations. The model captures the long-range dependencies and researchers’ preferences, by employing an end-to-end memory network and personalization module, respectively. We experimentally evaluate our method against baseline algorithms over two real-life datasets. The results indicate that the proposed method outperforms competing models.},
	pages = {6763--6785},
	number = {11},
	journaltitle = {Scientometrics},
	shortjournal = {Scientometrics},
	author = {Ali, Zafar and Qi, Guilin and Kefalas, Pavlos and Khusro, Shah and Khan, Inayat and Muhammad, Khan},
	urldate = {2024-10-31},
	date = {2022-11-01},
	langid = {english},
	keywords = {Cold-start problem, Memory network, Paper recommendation, Personalization, Recommender systems, {SPECTER}},
}

@article{bury_test_2023,
	location = {Stuttgart},
	title = {Test der Dualen Hochschule Stuttgart: Studierende nutzen {ChatGPT} häufig völlig unkritisch},
	url = {https://www.stuttgarter-zeitung.de/inhalt.test-der-dualen-hochschule-stuttgart-studierende-nutzen-chatgpt-haeufig-voellig-unkritisch.205a430c-8b8a-4f5b-b865-60c6029a2ad4.html},
	shorttitle = {Test der Dualen Hochschule Stuttgart},
	abstract = {Offenbar fehlt es an kritischem Bewusstsein: Bei einem Studienexperiment der Dualen Hochschule haben die Probanden teils sogar grobe Fehler des Chatbots unreflektiert übernommen. Man habe „erhebliche Defizite“ festgestellt.},
	journaltitle = {Stuttgarter Zeitung},
	author = {Bury, Mathias},
	urldate = {2024-10-31},
	date = {2023-05-09},
	langid = {german},
}

@inproceedings{page_astronomical_2004,
	location = {Berlin, Heidelberg},
	title = {The Astronomical Data Warehouse},
	isbn = {978-3-540-39908-7},
	doi = {10.1007/10857598_35},
	abstract = {The idea of the astronomical data warehouse has arisen as the natural extension of current trends in astronomical data archives, and from an analysis of the types of query likely to be sent to a virtual observatory. Data warehouses will be centres providing both data and computational facilities.},
	pages = {232--237},
	booktitle = {Toward an International Virtual Observatory},
	publisher = {Springer},
	author = {Page, Clive G.},
	editor = {Quinn, Peter J. and Górski, Krzysztof M.},
	date = {2004},
	langid = {english},
}
